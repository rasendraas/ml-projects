# -*- coding: utf-8 -*-
"""analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qyNr62XeLi91uie7XNVMWIwJOA-dLN3T

# [Predictive Analysis] - Air Quality & Pollution Assesment Quality Prediction

### Rasendra Akbar Satyatama - MC004D5Y1124

---

### **Domain Proyek: Lingkungan dan Kesehatan Masyarakat**

Kualitas udara merupakan aspek krusial dalam isu lingkungan dan kesehatan masyarakat. Menurut World Health Organization (WHO), polusi udara menyebabkan sekitar **7 juta kematian dini setiap tahun** di seluruh dunia karena paparan terhadap partikel halus dan gas beracun seperti PM2.5, NOâ‚‚, dan SOâ‚‚ \[1]. Wilayah dengan tingkat kepadatan penduduk tinggi atau dekat dengan kawasan industri cenderung memiliki tingkat polusi udara yang lebih tinggi, sehingga berdampak signifikan terhadap risiko penyakit pernapasan, kardiovaskular, dan berbagai gangguan kesehatan lainnya.

Dengan semakin pesatnya urbanisasi dan pertumbuhan industri, penting bagi pemerintah, organisasi lingkungan, dan masyarakat umum untuk memiliki sistem pemantauan dan prediksi kualitas udara yang dapat digunakan sebagai dasar pengambilan keputusan. Pendekatan konvensional dalam pemantauan kualitas udara, seperti penggunaan sensor stasioner, memiliki keterbatasan cakupan geografis dan biaya operasional yang tinggi. Oleh karena itu, pendekatan berbasis data dan machine learning dapat menjadi solusi yang efisien dan fleksibel dalam memperkirakan kondisi kualitas udara berdasarkan faktor lingkungan dan demografis.

Proyek ini berada dalam domain **lingkungan hidup dan kesehatan publik**, dengan fokus pada pengembangan model prediksi berbasis data untuk memetakan tingkat kualitas udara suatu wilayah secara otomatis. Dengan prediksi yang akurat, pemerintah dapat mengidentifikasi daerah risiko tinggi, mengatur kebijakan emisi, atau menyampaikan peringatan dini kepada masyarakat.

---

### Referensi:

\[1] World Health Organization (2021). *Air pollution*. Retrieved from [https://www.who.int/news-room/fact-sheets/detail/ambient-(outdoor)-air-quality-and-health](https://www.who.int/news-room/fact-sheets/detail/ambient-%28outdoor%29-air-quality-and-health)

## 1. Business Understanding

### **Problem Statements**

Dalam konteks urbanisasi dan industrialisasi yang pesat, kualitas udara menjadi perhatian utama karena dampaknya terhadap kesehatan masyarakat. Organisasi lingkungan hidup, pemerintah daerah, serta badan perencana kota membutuhkan alat prediksi yang andal untuk memperkirakan kualitas udara secara proaktif. Berdasarkan hal tersebut, berikut adalah pernyataan masalah yang diangkat:

1. **Pernyataan Masalah 1:**
   Bagaimana mengidentifikasi fitur lingkungan dan demografis yang paling berpengaruh terhadap tingkat kualitas udara di suatu wilayah?

2. **Pernyataan Masalah 2:**
   Bagaimana membangun model prediksi yang dapat mengklasifikasikan tingkat kualitas udara (Good, Moderate, Poor, Hazardous) secara akurat berdasarkan data lingkungan dan kependudukan?

3. **Pernyataan Masalah 3:**
   Bagaimana menentukan model yang dibangun mampu melakukan prediksi dengan performa optimal dan konsisten pada data baru?

---

### **Goals**

Untuk menjawab pernyataan masalah di atas, tujuan proyek ini dirumuskan sebagai berikut:

1. **Tujuan 1:**
   Melakukan eksplorasi data dan analisis korelasi untuk mengetahui fitur mana yang paling signifikan terhadap kualitas udara, seperti konsentrasi PM2.5, NOâ‚‚, kepadatan penduduk, atau jarak ke kawasan industri.

2. **Tujuan 2:**
   Membangun model machine learning klasifikasi multikelas yang dapat memprediksi kategori kualitas udara secara otomatis berdasarkan fitur numerik.

3. **Tujuan 3:**
   Melakukan evaluasi terhadap semua model yang digunakan untuk mengetahui prediksi dengan akurasi dan generalisasi terbaik.

---

### **Solution Statements**

Untuk mencapai tujuan-tujuan tersebut, solusi yang akan diimplementasikan meliputi:

1. **Eksperimen Beberapa Algoritma Klasifikasi:**
   Membangun dan membandingkan performa dari beberapa algoritma klasifikasi seperti:

   * K-Nearest Neighbors (KNN)
   * Random Forest
   * XGBoost

2. **Improvement Model dengan Hyperparameter Tuning:**
   Mengoptimalkan kinerja model terbaik melalui teknik hyperparameter tuning (Grid Search atau Random Search) guna meningkatkan performa prediksi.

3. **Evaluasi Berdasarkan Metrik yang Terukur:**
   Menggunakan metrik evaluasi seperti:

   * **Accuracy** untuk mengukur kebenaran prediksi secara keseluruhan.
   * **Precision, Recall, dan F1-Score** untuk menilai performa tiap kelas.
   * **Confusion Matrix** untuk melihat distribusi kesalahan klasifikasi.

4. **Visualisasi Hasil dan Interpretasi Fitur Penting:**
   Menggunakan *feature importance plot* dan *correlation heatmap* untuk menjelaskan fitur mana yang paling berkontribusi terhadap prediksi model.

---

## 2. Data Understanding

##### Link Sumber Data: https://www.kaggle.com/datasets/mssmartypants/water-quality/data

### 2.1 Data Loading
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_selection import f_classif
from sklearn.preprocessing import LabelEncoder
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, auc

df = pd.read_csv('updated_pollution_dataset.csv')
df.head()

len(df)

"""### 2.2 [Exploratory Data Analysis] - Deskripsi Variabel"""

df.info()

print("Statistik Deskriptif:")
df.describe()

grouped_means = df.groupby('Air Quality').mean(numeric_only=True)

print("Statistika Deskriptif (Rata-rata) per Kelas 'Air Quality':")
grouped_means

"""### 2.3 [Exploratory Data Analysis] - Menangani Missing Value dan Outliers"""

df.duplicated().sum()

# Cek jumlah missing value di setiap kolom
missing_values = df.isnull().sum()
print("Jumlah Missing Value per Kolom:\n")
print(missing_values)

numerical_cols = df.select_dtypes(include='number')

fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 12))
axes = axes.flatten()  # Ubah jadi 1D list agar mudah diakses

# Plot setiap boxplot
for i, col in enumerate(numerical_cols):
    sns.boxplot(y=df[col], color='lightcoral', ax=axes[i])
    axes[i].set_title(f'Boxplot {col}')

# Hapus axis kosong jika kolom < 9
for j in range(len(numerical_cols), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

# Deteksi outlier dengan metode IQR
def count_outliers_iqr(series):
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return ((series < lower_bound) | (series > upper_bound)).sum()

# Ambil semua kolom numerik, kecuali target
numerical_cols = df.select_dtypes(include='number').columns
if 'Air Quality' in df.columns:
    numerical_cols = numerical_cols.drop('Air Quality', errors='ignore')

# Cek dan print jumlah outlier per variabel
print("Jumlah outlier per variabel (berdasarkan IQR):")
for col in numerical_cols:
    outlier_count = count_outliers_iqr(df[col])
    print(f"{col}: {outlier_count} outlier")

"""### 2.4 [Exploratory Data Analysis] - Univariate Analysis"""

# --- 2. Proporsi Kategori (Grade) dengan Pie Chart ---
grade_counts = df['Air Quality'].value_counts()
plt.figure(figsize=(6, 6))
plt.pie(grade_counts, labels=grade_counts.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette('pastel'))
plt.title('Distribusi Grade Susu')
plt.axis('equal')
plt.show()

numerical_cols = df.select_dtypes(include='number').columns

fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 12))
axes = axes.flatten()

# Plot setiap kolom numerik ke subplot
for i, col in enumerate(numerical_cols):
    sns.histplot(data=df, x=col, bins=20, kde=True, color='mediumseagreen', edgecolor='white', ax=axes[i])
    axes[i].set_title(f'Distribusi dan KDE dari {col}')
    axes[i].set_xlabel(col)
    axes[i].set_ylabel('Frekuensi')
    axes[i].grid(True)

# Sembunyikan subplot yang tidak terpakai (jika ada)
for j in range(len(numerical_cols), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""### 2.5 [Exploratory Data Analysis] - Multivariate Analysis"""

numerical_cols = df.select_dtypes(include='number').columns.to_list()

# Buat grid plot 3x3 (asumsinya ada 9 fitur numerik)
fig, axes = plt.subplots(3, 3, figsize=(18, 12))
axes = axes.flatten()

for i, col in enumerate(numerical_cols):
    sns.barplot(
        x="Air Quality",
        y=col,
        data=df,
        estimator='mean',
        palette="Spectral",
        ax=axes[i]
    )
    axes[i].set_title(f'Rata-rata {col} untuk Setiap Kategori Air Quality')
    axes[i].set_xlabel('Air Quality')
    axes[i].set_ylabel(f'Mean {col}')
    axes[i].tick_params(axis='x', rotation=20)

plt.tight_layout()
plt.show()

sns.pairplot(df, hue='Air Quality', diag_kind='kde', palette='husl')
plt.suptitle('Pairplot Fitur Numerik Berdasarkan Kategori Air Quality', y=1.02)
plt.show()

corr_matrix = df[numerical_cols].corr()

# Buat mapping nama kolom baru untuk tampilan
col_rename_map = {
    'Proximity_to_Industrial_Areas': 'PIA',
    'Population_Density': 'PD',
}

renamed_corr = corr_matrix.rename(index=col_rename_map, columns=col_rename_map)

# Plot heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(renamed_corr, annot=True, fmt=".2f", cmap='Spectral', square=True)
plt.title('Matriks Korelasi antar Variabel Numerik')
plt.tight_layout()
plt.show()

"""### ANOVA F-test"""

X_f = df.drop(columns='Air Quality')
y_f = df['Air Quality']

f_scores, p_values = f_classif(X_f, y_f)

for col, score, p in zip(X_f.columns, f_scores, p_values):
    print(f'{col} â€” F-score: {score:.2f}, p-value: {p:.4f}')

"""Semua fitur punya p-value 0.0000 (sangat kecil), artinya semua fitur signifikan mempengaruhi atau berhubungan dengan target kelas kualitas udara.

F-score tertinggi ada pada fitur CO (Carbon Monoxide), kemudian Proximity_to_Industrial_Areas, NO2, dan seterusnya.

Fitur dengan F-score lebih besar berarti fitur itu lebih informatif dan berpengaruh lebih kuat dalam membedakan kelas kualitas udara.

### Feature Importance with Random Forest
"""

df_temp = df.copy()
le = LabelEncoder()
df_temp['AirQualityEncoded'] = le.fit_transform(df_temp['Air Quality'])

model = RandomForestClassifier(random_state=42)
model.fit(df_temp[numerical_cols], df_temp['AirQualityEncoded'])

feat_imp = pd.Series(model.feature_importances_, index=numerical_cols).sort_values(ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x=feat_imp.values, y=feat_imp.index, palette='mako')
plt.title('Feature Importance berdasarkan Random Forest')
plt.xlabel('Importance')
plt.ylabel('Fitur Numerik')
plt.tight_layout()
plt.show()

"""## 3. Data Preparation

### 3.1 Label Encoding dengan mapping pada Fitur Target
"""

ordinal_map = {
    'Good': 0,
    'Moderate': 1,
    'Poor': 2,
    'Hazardous': 3
}

df['Air Quality'] = df['Air Quality'].map(ordinal_map)

"""Mapping manual digunakan agar urutan label pada variabel target mewakili tingkatan kualitas udara secara logis. Berbeda dengan LabelEncoder yang mengurutkan label berdasarkan alfabet, mapping memungkinkan kita mengatur sendiri skala ordinal sesuai konteks (misal: Good < Moderate < Poor < Hazardous). Ini penting agar model dapat memahami bahwa kualitas udara memiliki tingkatan berurutan, bukan sekadar kategori acak.

### 3.2 Reduksi Dimensi dengan Principal Component Analysis (PCA)
"""

corr_matrix

"""### **Analisis Korelasi Antar Variabel: Justifikasi PCA**

Berdasarkan matriks korelasi antar variabel numerik, terlihat bahwa beberapa fitur memiliki hubungan korelasi yang cukup tinggi, terutama pada polutan partikulat. Berikut beberapa temuan utama:

#### 1. **Hubungan Sangat Kuat: PM2.5 & PM10**

* Korelasi: **0.97** (sangat tinggi, nyaris sempurna).
* Artinya: Informasi dari PM2.5 dan PM10 sangat mirip (redundan).
* Implikasi: Salah satu dari kedua fitur ini bisa digabung/diringkas menggunakan PCA agar tidak mendominasi model dan mengurangi redundansi data.

#### 2. **Hubungan Polutan Gas (NO2, SO2, CO) Moderat - Kuat**

* NO2 & CO: **0.71**
* SO2 & CO: **0.68**
* NO2 & SO2: **0.57**
* Meskipun memiliki korelasi yang cukup kuat, ketiga variabel ini tetap dipertahankan secara individual agar informasi spesifik dari masing-masing fitur tidak hilang, terutama karena karakteristik pencemarnya bisa berbeda.

#### 3. **Proximity\_to\_Industrial\_Areas Berkorelasi Negatif Kuat dengan Polutan**

* CO & Proximity: **-0.71**
* NO2 & Proximity: **-0.61**
* Artinya: Semakin dekat ke kawasan industri, polusi semakin tinggi (sesuai ekspektasi).
* Variabel ini tetap dipertahankan karena merepresentasikan faktor lokasi yang unik.

#### 4. **Faktor Cuaca (Temperature, Humidity) Berkorelasi Sedang dengan Polutan**

* Temperature & CO: **0.69**
* Humidity & CO: **0.57**
* Meski tidak sekuat PM2.5 dan PM10, faktor cuaca memiliki variasi informasi tersendiri, sehingga dipertahankan.

---

### **Justifikasi Reduksi Dimensi via PCA**

> "Dari hasil analisis korelasi, disimpulkan bahwa hanya fitur **PM2.5** dan **PM10** yang memiliki tingkat korelasi sangat tinggi (**0.97**), menunjukkan informasi yang tumpang tindih. Oleh karena itu, PCA difokuskan pada kedua variabel ini untuk merangkum variasi data menjadi satu komponen utama. Fitur lainnya tetap dipertahankan secara individual agar karakteristik spesifik masing-masing variabel tetap terjaga."

---
"""

pca_features = df[['PM2.5', 'PM10']]

pca = PCA(n_components=2, random_state=123)
pca.fit(pca_features)

princ_comp = pca.transform(pca_features)

print('Explained Variance Ratio:', pca.explained_variance_ratio_.round(3))

"""Berdasarkan hasil PCA terhadap variabel PM2.5 dan PM10, satu komponen utama mampu menjelaskan sebesar 98,7% variasi data keduanya. Ini menunjukkan bahwa informasi dari PM2.5 dan PM10 sangat tumpang tindih, sehingga keduanya dapat diringkas menjadi satu fitur utama tanpa kehilangan informasi penting. Reduksi dimensi ini bertujuan mengurangi redundansi data secara efektif dan menjaga efisiensi analisis."""

pca = PCA(n_components=1, random_state=123)
pca.fit(df[['PM2.5', 'PM10']])

df['Particulate_Matter'] = pca.transform(df[['PM2.5', 'PM10']]).flatten()

df.drop(['PM2.5', 'PM10'], axis=1, inplace=True)

df

"""### 3.3 Data Train-Test-Split"""

X = df.drop(['Air Quality'], axis=1)  # fitur tanpa target
y = df['Air Quality']  # target

# Split data 80:20
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=123, stratify=y)

print(f'Total # of samples in whole dataset: {len(X)}')
print(f'Total # of samples in train dataset: {len(X_train)}')
print(f'Total # of samples in test dataset: {len(X_test)}')

"""Dengan 5000 data, membagi 80% untuk pelatihan (4000 data) dan 20% untuk pengujian (1000 data) memberikan cukup data bagi model untuk belajar dengan baik, sekaligus menyisakan data yang memadai untuk mengukur performa model secara objektif. Proporsi ini cukup umum digunakan karena menjaga keseimbangan antara kebutuhan generalisasi model dan efektivitas pelatihan.

### 3.4 Data Scaling (RobustScaler)
"""

scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train)

print(X_train_scaled)

"""Dalam dataset ini, beberapa variabel numerik terdeteksi memiliki outliers yang cukup signifikan. Penggunaan teknik standarisasi berbasis rata-rata dan standar deviasi, seperti StandardScaler, menjadi kurang tepat karena mudah terpengaruh oleh outliers, sehingga dapat menyebabkan skala data menjadi bias. Oleh karena itu, digunakan RobustScaler yang melakukan standarisasi dengan memanfaatkan median dan interquartile range (IQR), sehingga lebih tahan terhadap pengaruh nilai ekstrem. Pendekatan ini memastikan skala data lebih representatif tanpa distorsi dari outliers.

## 4. Model Development

### 4.1 Modeling dengan KNN
"""

knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train_scaled, y_train)

"""### 4.2 Modeling dengan Random Forest"""

rf_model = RandomForestClassifier(n_estimators=100, random_state=123)
rf_model.fit(X_train_scaled, y_train)

"""### 4.3 Modeling dengan XGBoost"""

xgb_model = XGBClassifier(n_estimators=100, random_state=123, use_label_encoder=False, eval_metric='mlogloss')
xgb_model.fit(X_train_scaled, y_train)

"""## 5. Model Evaluation"""

X_test_scaled = scaler.transform(X_test)

models = {
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'Random Forest': RandomForestClassifier(random_state=123),
    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=123)
}

results = {}
y_test_encoded = y_test  # karena tadi udah di label encoded kan

for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    y_train_pred = model.predict(X_train_scaled)
    y_test_pred = model.predict(X_test_scaled)

    results[name] = {
        'train_acc': accuracy_score(y_train, y_train_pred),
        'test_acc': accuracy_score(y_test, y_test_pred),
        'report': classification_report(y_test, y_test_pred, output_dict=True),
        'conf_matrix': confusion_matrix(y_test, y_test_pred),
        'y_test_pred_proba': model.predict_proba(X_test_scaled)
    }

"""### 5.1 Train-Test Accuracy & Classification Report"""

# ==== PLOTTING AKURASI ====
acc_df = pd.DataFrame({
    'Model': list(results.keys()),
    'Train Accuracy': [results[m]['train_acc'] for m in results],
    'Test Accuracy': [results[m]['test_acc'] for m in results]
})

acc_df.set_index('Model').plot(kind='bar', figsize=(8, 5), ylim=(0, 1), colormap='Spectral')
plt.title('Train & Test Accuracy per Model')
plt.ylabel('Accuracy')
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

acc_table = pd.DataFrame({
    'Model': list(results.keys()),
    'Train Accuracy': [f"{results[m]['train_acc']:.4f}" for m in results],
    'Test Accuracy': [f"{results[m]['test_acc']:.4f}" for m in results]
})

display(acc_table)

report_df = pd.concat({m: pd.DataFrame(results[m]['report']).T for m in results}, axis=1)
display(report_df.style.format("{:.2f}").set_caption("Classification Report Comparison"))

"""### 5.2 Confusion Matrix"""

# ==== CONFUSION MATRIX BERJEJER ====
fig, axs = plt.subplots(1, 3, figsize=(15, 4))

for ax, (name, res) in zip(axs, results.items()):
    sns.heatmap(res['conf_matrix'], annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax)
    ax.set_title(f'{name} Confusion Matrix')
    ax.set_xlabel('Predicted')
    ax.set_ylabel('Actual')

plt.tight_layout()
plt.show()

"""### 5.3 AUC-ROC Curve"""

plt.figure(figsize=(8, 6))

for name, res in results.items():
    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    n_classes = res['y_test_pred_proba'].shape[1]

    for i in range(n_classes):
        fpr[i], tpr[i], _ = roc_curve(y_test_encoded == i, res['y_test_pred_proba'][:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    # Macro-average ROC
    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))
    mean_tpr = np.zeros_like(all_fpr)
    for i in range(n_classes):
        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])
    mean_tpr /= n_classes

    plt.plot(all_fpr, mean_tpr, label=f'{name} (AUC = {auc(all_fpr, mean_tpr):.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve Comparison')
plt.legend(loc='lower right')
plt.tight_layout()
plt.show()

"""## 6. Conclusion"""

summary_data = {
    'KNN': {'Train Accuracy': 0.9450, 'Test Accuracy': 0.9140, 'AUC': 0.97, 'Macro F1': 0.87},
    'Random Forest': {'Train Accuracy': 1.0000, 'Test Accuracy': 0.9490, 'AUC': 0.99, 'Macro F1': 0.92},
    'XGBoost': {'Train Accuracy': 1.0000, 'Test Accuracy': 0.9450, 'AUC': 0.99, 'Macro F1': 0.92},
}

summary_df = pd.DataFrame(summary_data).T

plt.figure(figsize=(8, 5))
sns.heatmap(summary_df, annot=True, cmap='YlGnBu', fmt='.2f', linewidths=0.5, cbar_kws={"shrink": 0.7})
plt.title('Model Performance Summary Heatmap')
plt.yticks(rotation=0)
plt.show()

"""## **Kesimpulan Evaluasi Model Klasifikasi**

### ðŸ”¹ **Akurasi Model**

| Model         | Train Accuracy | Test Accuracy |
| ------------- | -------------- | ------------- |
| KNN           | 0.9450         | 0.9140        |
| Random Forest | 1.0000         | 0.9490        |
| XGBoost       | 1.0000         | 0.9450        |

> Random Forest dan XGBoost menunjukkan akurasi train sempurna (1.0000), sedangkan KNN lebih rendah namun masih baik. Di data test, Random Forest mencatat akurasi tertinggi (0.9490), diikuti XGBoost (0.9450) dan KNN (0.9140).

---

### ðŸ”¹ **Classification Report (Test Data)**

| Class            | KNN (F1-score) | Random Forest (F1-score) | XGBoost (F1-score) |
| ---------------- | -------------- | ------------------------ | ------------------ |
| Good             | 0.99           | 1.00                     | 1.00               |
| Hazardous        | 0.92           | 0.96                     | 0.95               |
| Moderate         | 0.81           | 0.88                     | 0.87               |
| Poor             | 0.77           | 0.85                     | 0.86               |
| **Macro Avg**    | 0.87           | 0.92                     | 0.92               |
| **Weighted Avg** | 0.91           | 0.95                     | 0.94               |

> Random Forest dan XGBoost unggul merata di semua kelas dibanding KNN, terutama pada kelas Moderate & Poor yang lebih sulit diprediksi.

---

### ðŸ”¹ **AUC-ROC Score**

| Model         | AUC Score |
| ------------- | --------- |
| KNN           | 0.97      |
| Random Forest | 0.99      |
| XGBoost       | 0.99      |

> AUC-ROC menunjukkan Random Forest dan XGBoost memiliki performa klasifikasi sangat baik dengan AUC 0.99, sedangkan KNN sedikit lebih rendah di 0.97 namun masih tergolong excellent.

---

### **Kesimpulan Akhir**

> Secara keseluruhan, **Random Forest** menjadi model terbaik dalam hal akurasi, f1-score, dan AUC. XGBoost memiliki performa yang sangat mendekati Random Forest, namun sedikit lebih rendah di test accuracy dan kelas minoritas. Model KNN cukup baik, namun kalah konsisten di kelas Moderate & Poor.

"""